{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s: %(levelname)s: %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cuttext_mysql(sql_database, sql_table, cols_name, year):\n",
    "    import mysql.connector\n",
    "    sql_db = mysql.connector.connect(\n",
    "        host = '127.0.0.1',\n",
    "        user = 'root',\n",
    "        password = \"\",\n",
    "        database = sql_database\n",
    "    )\n",
    "    cursor = sql_db.cursor()\n",
    "    \n",
    "    # to check whether TABLE EXISTS OR NOT\n",
    "    cursor.execute(\"SHOW TABLES LIKE '{}'\".format(sql_table))\n",
    "    temp_result = cursor.fetchone()\n",
    "    if (temp_result):\n",
    "        logging.info(\"TABLE {} exists in DATABASE {}\".format(sql_table, sql_database))\n",
    "    else:\n",
    "        logging.info(\"TABLE {} exists in DATABASE {}\".format(sql_table, sql_database))\n",
    "        \n",
    "    #select_sql = \"SELECT {}, GROUP_CONCAT({} SEPARATOR '') FROM {} WHERE {}<'2021' GROUP BY {}\".format(cols_name[0], cols_name[1], sql_table, cols_name[0], cols_name[0])\n",
    "    #select_sql = \"SELECT project_name, {} FROM {} WHERE {}='{}'\".format(cols_name[1], sql_table, cols_name[0], year)\n",
    "    select_sql = \"SELECT project_id, {} FROM {} WHERE {}='{}'\".format(cols_name[1], sql_table, cols_name[0], year)\n",
    "    print(select_sql)\n",
    "    cursor.execute(select_sql)\n",
    "    result = cursor.fetchall()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load cut word string into list\n",
    "def word_to_list(cut_article):\n",
    "    cut_word_list = []\n",
    "    words = \"\"\n",
    "    for c in cut_article:\n",
    "        if c.isspace():\n",
    "            cut_word_list.append(words)\n",
    "            words = \"\"\n",
    "        else:\n",
    "            words += c\n",
    "    return cut_word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the stopword from flingv_description_cut.txt\n",
    "def load_stopwords(filename):\n",
    "    f = open(filename, \"r\", encoding='UTF-8')\n",
    "    lines = f.readlines()\n",
    "    for idx, val in enumerate(lines):\n",
    "        lines[idx] = lines[idx].strip('\\n')\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main block\n",
    "# normal tf-idf, loop for each year\n",
    "for y in range(2012, 2021):\n",
    "    sql_database = \"crowdfunding_db\"\n",
    "    #sql_table = \"v3_latest_zeczec_basic_project_information\"\n",
    "    sql_table = \"v6_latest_flyingv_basic_project_information\"\n",
    "    column_name = [\"YEAR(start_date)\", \"description_text_cut\"]\n",
    "    cut_year = get_cuttext_mysql(sql_database, sql_table, column_name, y)\n",
    "    logging.info(\"GET cut_text! year: {} length: {}\".format(y, len(cut_year)))\n",
    "    \n",
    "    # cut the word & store as list & eliminate stopword\n",
    "    cut_corpus = []\n",
    "    stopword = load_stopwords('tc_stopwords.txt')\n",
    "    for cy in cut_year:\n",
    "        cut_article = cy[1].strip()\n",
    "        cut_article = cut_article.replace('\\n', '')\n",
    "        cut_article_list = word_to_list(cut_article)\n",
    "\n",
    "        no_stopword_list = []\n",
    "        for w in cut_article_list:\n",
    "            if (len(w)>=2) and (w not in stopword):\n",
    "                no_stopword_list.append(w)\n",
    "        cut_word_len = len(no_stopword_list)\n",
    "        temp_list = [cy[0], cut_word_len, no_stopword_list]\n",
    "        cut_corpus.append(temp_list)\n",
    "    logging.info(\"cut_corpus DONE! year: {} length: {}\".format(y, len(cut_year)))\n",
    "    \n",
    "    # tf-1\n",
    "    # count occurence of each words in each project description\n",
    "    words_count = []\n",
    "    for p in cut_corpus:\n",
    "        count = {}\n",
    "        for word in p[2]:\n",
    "            if word in count:\n",
    "                count[word] += 1\n",
    "            else:\n",
    "                count[word] = 1\n",
    "        words_count.append([p[0], p[1], count])\n",
    "    words_frequency = []\n",
    "    #tf-2\n",
    "    for wc in words_count:\n",
    "        all_count = sum(wc[2].values())\n",
    "        fre = {}\n",
    "        for word, count in wc[2].items():\n",
    "            fre[word] = round(count/all_count, 4)\n",
    "        words_frequency.append([wc[0], fre])\n",
    "        \n",
    "    # idf-1\n",
    "    # count occurence of each words in each project description\n",
    "    words_count = []\n",
    "    for p in cut_corpus:\n",
    "        count = {}\n",
    "        for word in p[2]:\n",
    "            if word in count:\n",
    "                count[word] += 1\n",
    "            else:\n",
    "                count[word] = 1\n",
    "        words_count.append(count)\n",
    "    #print(len(words_count))\n",
    "\n",
    "    # because wrods_count contains unique words for each description\n",
    "    all_words = []\n",
    "    for word in words_count:\n",
    "        all_words.extend(list(word.keys()))\n",
    "    #all_words[:10]\n",
    "    # the occurence in desciption of each word\n",
    "    occurences_of_word = {}\n",
    "    for word in all_words:\n",
    "        if word in occurences_of_word:\n",
    "            occurences_of_word[word] += 1\n",
    "        else:\n",
    "            occurences_of_word[word] = 1\n",
    "    #print(len(occurences_of_word.items()))\n",
    "    # idf-2\n",
    "    import math\n",
    "    inverse_doc_fre = []\n",
    "    print(len(words_count))\n",
    "    for wc in words_count:\n",
    "        inv_fre = {}\n",
    "        for w in wc.keys():\n",
    "            all_description = len(words_count)\n",
    "            occurences = occurences_of_word[w]\n",
    "            inv_fre[w] = math.log(round(all_description/occurences, 4)) # base=e\n",
    "        inverse_doc_fre.append(inv_fre)\n",
    "    \n",
    "    # tf-idf\n",
    "    all_tf_idf = []\n",
    "    for i, p in enumerate(words_frequency):\n",
    "        tf_idf = {}\n",
    "        for word, freq in p[1].items():\n",
    "            tf_idf[word] = freq*inverse_doc_fre[i][word]\n",
    "        all_tf_idf.append([p[0], tf_idf])\n",
    "    \n",
    "    # keyword for the year: count the occurence of the word within top k keyword in each description\n",
    "    # pick top k keyword from each description\n",
    "    k = 100\n",
    "    top_k_keyword = []\n",
    "    for p in all_tf_idf:\n",
    "        temp_word_list = sorted(p[1].items(), key=lambda item:item[1], reverse=True)\n",
    "        #print(p[0], len(temp_word_list))\n",
    "        if k>len(temp_word_list): # avoid not enough word in the description\n",
    "            k=len(temp_word_list)\n",
    "        if len(temp_word_list)!=0:\n",
    "            for i in range(k):\n",
    "                top_k_keyword.append(temp_word_list[i][0])\n",
    "    print(len(top_k_keyword))\n",
    "    # count the occurence of words in top_k_keyword\n",
    "    occ_of_keyword = {}\n",
    "    for word in top_k_keyword:\n",
    "        if word in occ_of_keyword:\n",
    "            occ_of_keyword[word] += 1\n",
    "        else:\n",
    "            occ_of_keyword[word] = 1\n",
    "    #occ_of_keyword\n",
    "    keyword_list = sorted(occ_of_keyword.items(), key=lambda item:item[1], reverse=True)\n",
    "    print(keyword_list[:10])\n",
    "\n",
    "    keyword_cols = ['word', 'occurence']\n",
    "    keyword_df = pd.DataFrame(columns = keyword_cols)\n",
    "    for w in keyword_list:\n",
    "        temp_df = pd.DataFrame([[w[0], w[1]]], columns=keyword_cols)\n",
    "        keyword_df = keyword_df.append([temp_df], ignore_index=True)\n",
    "    #csv_filename = 'zeczec_{}_top_keyword_tfidf.csv'.format(y)\n",
    "    csv_filename = 'flyingv_{}_top_keyword_tfidf.csv'.format(y)\n",
    "    keyword_df.to_csv(csv_filename, encoding='utf-8-sig', index=False)\n",
    "    print(keyword_df[:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
